---
title: "Trabajo Detección de Anomalías"
author: "Antonio David Villegas Yeguas"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Bibliotecas y funciones a utilizar

En esta sección simplemente cargamos los paquetes y funciones que utilizaremos a lo largo del trabajo.

```{r}
source("OutliersLibrerias.R")
source("OutliersFunciones_byCubero.R")
# para leer archivos .mat, formato de nuestro dataset
library(rmatio)
```

# 2. Dataset

Para realizar el trabajo se utilizará el conjunto de datos sobre vinos [wine](http://odds.cs.stonybrook.edu/wine-dataset/). Este conjunto de datos contiene información sobre trece atributos de distintas muestras de vino obtenidas de tres cultivos distintos. Los datos originales estaban pensados para resolver un problema de clasificación, en el que el objetivo era predecir el cultivo al que pertenecía la muestra, sin embargo este conjunto ha sido adaptado por la comunidad de http://odds.cs.stonybrook.edu/ para convertirlo en un conjunto de datos con anomalías, donde se han reducido las observaciones del primer cultivo a diez observaciones, que actuarán como outliers, mientras que las observaciones del segundo y tercer cultivo no se han modificado.

Estos datos se proporcionan en formato MATLAB, por lo que utilizaremos el paquete `rmatio` para leerlos. El fichero dado no contiene la información original sobre el cultivo del que proviene cada observación, contiene una matriz X con los trece atributos del vino, y una columna Y que nos dice si un dato es outlier o no.

```{r}
# Leemos los datos
wine_completo <- read.mat("wine.mat") 
wine <- as.data.frame(wine_completo$X)
wine_outliers <- wine_completo$y

# Asignamos los nombres a las columnas
names(wine) <- c("Alcohol", "Malic_acid", "Ash", "Alcalinity_of_ash", "Magnesium", "Total_phenols", "Flavanoids", "Nonflavanoid_phenols", "Proanthocyanins", "Color_intensity", "Hue", "OD280/OD315_of_diluted_wines", "Proline")

```


Al igual que en el guión de prácticas, utilizaremos distintos objetos auxiliares que nos ayudarán a realizar el trabajo.

- `datos`: Data frame con los datos de wine.
- `datos.num`: Data frame con las columnas de wine que sean de tipo numérico.
- `indice.columna`: Indice de la columna con la que trabajaremos.
- `nombre.columna`: Nombre de la columna con la que trabajaremos.

Además, eliminaremos las filas que contengan valores perdidos y las columnas que sean valores ordinales.


```{r echo = FALSE}
# creamos los conjuntos de datos

datos <- wine

columnas.num <- sapply(c(1:ncol(datos)), function(x) is.numeric(datos[, x]))
cat("Columnas numéricas: ")
columnas.num

datos.num <- datos[, columnas.num]
cat("Seis primeras filas de los datos: ")
head(datos.num)


datos.num <- na.omit(datos.num)
```
Como podemos ver en el resultado, las 13 columnas del conjunto de datos son numéricas, además de no tener ningún valor ordinal o pocos valores distintos, por lo que no eliminaremos ninguna columna.


# 3. DETECCION DE OUTLIERS EN UNA DIMENSION

En este apartado calcularemos los outliers 1-variantes, es decir, con respecto a una única columna.

## 3.1 OUTLIERS IQR

En este apartado se utilizará el método IQR para detección de outliers. Como ya hemos visto en la asignatura, este método solo se debería aplicar a datos que sigan una distribución normal, sin embargo funciona bastante bien siempre que la distribución no sea muy rara.

Lo primero que haremos será ver los histogramas de todas las columnas del conjunto de datos:

```{r results = "hide"}
# mostramos el histograma de todas las columnas
par(mfrow = c(2,3))
sapply(c(1:ncol(datos.num)), function(x) hist(datos.num[,x], main = "", xlab = names(datos.num)[x]) )
par(mfrow = c(1,1))
```

Como vemos, no parece que ninguna columna siga una distribución rara, a excepción de la columna `OD280/OD315_of_diluted_wines`, que parece seguir una bimodal, al tener dos picos claramente diferenciados.

Se ha decidido seleccionar la columna 13, `Proline`, ya que se trata de una columna con una distribución semejante a la normal, aunque podemos ver que tiene valores en la cola derecha, lo que nos puede ayudar a intuir que encontraremos outliers en esta columna. Vamos a comprobarlo con el método IQR.

```{r}
# variables a usar en el apartado

indice.columna = 13
columna <- datos.num[, indice.columna]
nombre.columna <- names(datos.num)[indice.columna]
```

### 3.1.1 Obtencion de outliers IQR

Al igual que en el guión de prácticas, calcularemos los cuartiles de la columna, así como su distancia intercuartil:

```{r}
# Calculo del cuartil primero, tercero e irq
cuartiles <- quantile(columna, probs = c(0.25, 0.75))
cuartil.primero <- cuartiles[1]
cuartil.tercero <- cuartiles[2]

iqr <- IQR(columna)

cuartil.primero
cuartil.tercero
iqr
```

Tras obtener el primer y tercer cuartil pasamos a obtener los extremos que delimitarán si consideramos un valor outlier, así como outlier extremo.

```{r}

# calculo de extremos que delimitan los outliers

extremo.superior.outlier.IQR <- cuartil.tercero + iqr * 1.5
extremo.inferior.outlier.IQR <- cuartil.primero - iqr * 1.5
extremo.superior.outlier.IQR.extremo <- cuartil.tercero + iqr * 3
extremo.inferior.outlier.IQR.extremo <- cuartil.primero - iqr * 3

extremo.superior.outlier.IQR
extremo.inferior.outlier.IQR
extremo.superior.outlier.IQR.extremo
extremo.inferior.outlier.IQR.extremo
```

Una vez conocemos estos extremos, vamos a observar si tenemos outliers IQR en la columna seleccionada, para ello simplemente comprobamos si el valor de cada observación está fuera del rango comprendido entre los extremos inferiores y superiores calculados anteriormente:

```{r}
# Contruimos vectores logicos que nos dicen si cada registro es outlier o no
son.outliers.IQR <- columna < extremo.inferior.outlier.IQR | columna > extremo.superior.outlier.IQR
son.outliers.IQR.extremos <- columna < extremo.inferior.outlier.IQR.extremo | columna > extremo.superior.outlier.IQR.extremo

head(son.outliers.IQR)
sum(son.outliers.IQR)

head(son.outliers.IQR.extremos)
sum(son.outliers.IQR.extremos)
```

Como podemos ver en los resultados, en esta columna tenemos ocho outliers IQR, de los cuales dos de ellos son outliers extremos.


### 3.1.2 Indices y valores de los outliers IQR

Una vez tenemos vectores lógicos que nos indican que valores son outliers IQR, en esta sección obtendremos sus índices y valores.

Para obtener los índices utilizaremos la función `which` ya que nos devolverá el índice del vector lógico cuyo valor sea `TRUE`, y con los índices podremos obtener los valores. Tabmién obtendremos un frame con las filas de los valores que son outliers, de cara a estudiarlos por separado. Aunque en el guión de prácticas se obtenian los nombres de las filas, en este caso esto se ha omitido ya que en este dataset las filas no tienen nombre, por lo que el nombre será el mismo que el indice de la columna.

```{r}
claves.outliers.IQR <- which(son.outliers.IQR)
df.outliers.IQR <- datos.num[claves.outliers.IQR,]
valores.outliers.IQR <- columna[claves.outliers.IQR]

claves.outliers.IQR.extremos <- which(son.outliers.IQR.extremos)
df.outliers.IQR.extremos <- datos.num[claves.outliers.IQR.extremos,]
valores.outliers.IQR.extremos <- columna[claves.outliers.IQR.extremos]

claves.outliers.IQR
df.outliers.IQR
valores.outliers.IQR

claves.outliers.IQR.extremos
df.outliers.IQR.extremos
valores.outliers.IQR.extremos

```

Vemos como todos los indices obtenidos son los de las filas de la uno a la diez (a excepción de la tres y la cinco), por lo que podemos intuir que los resultados son correctos ya que como vimos en la descripción del dataset, los diez primeros valores correspondían a las observaciones del primer cultivo, del que precisamente se habían mantenido diez instancias para que actuaran como outliers.


### 3.1.3 Cómputo de los outliers de IQR con funciones

Otra opción para obtener los outliers IQR habría sido utilizar las funciones dadas, con las que se obtienen los mismos resultados:


```{r echo = FALSE}
son.outliers.IQR     = son_outliers_IQR (datos.num, indice.columna)
head(son.outliers.IQR)

claves.outliers.IQR  = claves_outliers_IQR (datos.num, indice.columna)
claves.outliers.IQR

son.outliers.IQR.extremos    = son_outliers_IQR (datos.num, indice.columna, 3)
head(son.outliers.IQR.extremos)

claves.outliers.IQR.extremos = claves_outliers_IQR (datos.num, indice.columna, 3)
claves.outliers.IQR.extremos

```



### 3.1.4 Desviacion de los outliers con respecto a la media de la columna

Tras obtener los outliers IQR así como sus valores, vamos a calcular la desviación con respecto a la media de la columna. Para este apartado normalizaremos los datos mediante el método z-score, de cara a poder trabajar como si lo hicieramos con una distribución N(0, 1), en la que podemos decir que un valor es algo inusual si no está en el rango [-2, 2], y bastante inusial si no está en el rango [-3, 3].


```{r echo = FALSE}
datos.num.norm = scale(datos.num)
cat("Datos normalizados por z-score:")
head(datos.num.norm)
columna.norm   = datos.num.norm[, indice.columna]
```

Una vez tenemos los datos normalizados, para obtener los valores de los outliers IQR normalizados simplemente consultamos sus valores ya que disponemos de los indices gracias a los apartados anteriores:

```{r}
valores.outliers.IQR.norm <- columna.norm[claves.outliers.IQR]
valores.outliers.IQR.norm
```

Con esto podemos comprobar que efectivamente son valores raros, al estar por encima (o casi por encima) de dos, e incluso los extremos por encima de tres, mientras que antes al obtener un valor de `Proline` de 1270 no sabíamos si era un valor inusual o no.

También podemos ver el valor de las otras columnas para los outliers IQR de la columna `Proline`:

```{r}
datos.num.norm.outliers.IQR <- datos.num.norm[claves.outliers.IQR,]
datos.num.norm.outliers.IQR
```

En este caso no tienen valores inusuales, a excepción de la segunda fila, en la que el valor de `Alcohol` si es un valor algo inusual.



### 3.1.5 Gráfico

En este apartado mostraremos gráficamente los valores obtenidos en los apartados anteriores utilizando las funciones gráficas dadas. En concreto utilizaremos los datos normalizados y los outliers IQR obtenidos:

```{r}
par(mfrow = c(1,1))

plot_2_colores(columna.norm, claves.outliers.IQR, titulo = nombre.columna)
```

Podemos ver claramente como los valores detectados como outliers son valores inusuales para la columna.

También podemos ver los outliers extremos:

```{r}
plot_2_colores(columna.norm, claves.outliers.IQR.extremos, titulo = nombre.columna)
```


# 3.1.6 Diagramas de cajas

También podemos ver gráficamente las observaciones que son outliers con un diagrama de cajas utilizando los datos normalizados:

```{r}

diag_caja_outliers_IQR(datos.num.norm, indice.columna)

```

También podemos utilizar los nombres de las filas, para ver como los dos puntos más alejados de la caja se tratan de los outliers extremos, los indices 9 y 10:

```{r}
diag_caja(datos.num.norm, indice.columna, claves.a.mostrar = claves.outliers.IQR)

```

Además de esto podemos observar el resto de columnas, para observar si también tienen un valor inusual:

```{r}
diag_caja_juntos(datos.num, titulo = "Outliers en alguna columna", claves.a.mostrar = claves.outliers.IQR)
```

Vemos como los outliers obtenidos en la columna `Proline` no presentan valores inusuales en el resto de columnas, a excepción de la fila 2 en la columna `Alcohol`.


## 3.2 Tests de hipotesis (OPCIONAL)

### 3.2.1 Objetivo

En esta sección vamos a determinar si el valor más alejado de la media puede considerarse como outlier. Para esto utilizaremos un test estadistico donde la hipotesis nula será que el valor más alejado de la media no es un outlier.


### 3.2.2 Comprobación de la hipótesis de Normalidad

El test de Grubbs, test que utilizaremos para comprobar si la hipotesis nula se rechaza o no, asume que los datos deben seguir una distribución normal sin tener en cuenta el valor más alejado de la media. Por este motivo, lo primero que haremos será comprobar visualmente si nuestra distribución se asemeja a una normal:

```{r}
ajusteNormal = fitdist(columna , "norm")
denscomp (ajusteNormal,  xlab = nombre.columna)
```

### 3.2.3 Test de Grubbs

Al ver que los datos siguen una distribución relativamente similar a la normal, aplicamos el test de Grubbs:

```{r}
test.de.Grubbs = grubbs.test(columna, two.sided = TRUE)
test.de.Grubbs$p.value
```

El p-value es menor a 0.05, por lo que rechazamos la hipotesis nula, así que podemos considerar que el valor más alejado de la media es un outlier. Obtenemos ese valor con la función `outlier`:

```{r}
valor.outlier = outlier(columna)
valor.outlier
```

Para obtener el índice del outlier utilizaremos el parámetro `logical` de la función `outlier`, combinado con `which` para saber el índice.

```{r}
es.outlier = outlier(columna, logical = TRUE)
clave.outlier = which( es.outlier == TRUE)
clave.outlier
```

Vemos como el índice obtenido se trata del 9, un valor que anteriormente vimos que se trataba de un outlier extremo utilizando el método IQR.

### 3.2.4 Test de Normalidad

Tras obtener el índice del elemento que es un outlier, pasamos a aplicar el test de normalidad de Shapiro-Wilk:

```{r}
datos.sin.outlier = columna[-clave.outlier]
datos.sin.outlier

shapiro.test(datos.sin.outlier)
goodness_fit = gofstat(ajusteNormal)
goodness_fit$adtest
```

En nuestro caso el test de Anderson-Darling no se ha podido aplicar porque hay pocos datos, mientras que en el test de Shapiro-Wilk se rechaza la hipotesis nula, por lo que los datos no siguen una distribución normal. Esto tal vez se deba a que todavía existen valores anómalos, como vimos con el cómputo de outliers IQR, ya que la décima observación también era considerada como un outlier extremo por IQR, y varias filas eran consideradas outliers IQR.

De cara a automatizar este proceso se ha escrito la siguiente función, que como vemos obtiene los mismo resultados que hemos obtenido manualmente:

```{r}
#######################################################################
# Aplica el test de Grubbs sobre la columna ind.col de datos y devuelve una lista con:

# nombre.columna: Nombre de la columna datos[, ind.col]
# clave.mas.alejado.media: Clave del valor O que está más alejado de la media
# valor.mas.alejado.media: Valor de O en datos[, ind.col]
# nombre.mas.alejado.media: Nombre de O en datos
# es.outlier: TRUE/FALSE dependiendo del resultado del test de Grubbs sobre O
# p.value:  p-value calculado por el test de Grubbs
# es.distrib.norm: Resultado de aplicar el test de Normalidad 
#    de Shapiro-Wilks sobre datos[, ind.col]
#    El test de normalidad se aplica sin tener en cuenta el 
#    valor más alejado de la media (el posible outlier O)
#    TRUE si el test no ha podido rechazar
#       -> Sólo podemos concluir que los datos no contradicen una Normal
#    FALSE si el test rechaza 
#       -> Los datos no siguen una Normal

# Requiere el paquete outliers

test_Grubbs <- function(data.frame, indice.columna, alpha = 0.05) {
	resultado <- list()
	resultado$nombre.columna <- names(data.frame)[indice.columna]
	resultado$clave.mas.alejado.media <- which( outlier(data.frame[,indice.columna], logical = TRUE) == TRUE ) 
	resultado$valor.mas.alejado.media <- data.frame[resultado$clave.mas.alejado.media, indice.columna] 
	resultado$nombre.mas.alejado.media <- nombres_filas(data.frame, resultado$clave.mas.alejado.media)
	
	test.de.Grubbs <- grubbs.test(data.frame[, indice.columna], two.sided = TRUE)
	
	resultado$p.value <- test.de.Grubbs$p.value
	resultado$es.outlier <- test.de.Grubbs$p.value <= alpha
	
	
	datos.sin.outlier <- data.frame[-resultado$clave.mas.alejado.media, indice.columna]
	datos.sin.outlier
	
	resultado$p.value.test.normalidad <- shapiro.test(datos.sin.outlier)$p.value
	resultado$es.distrib.norm <- resultado$p.value.test.normalidad > alpha
	
	resultado
}


test.Grubbs.datos.num = test_Grubbs(datos.num, indice.columna)

test.Grubbs.datos.num
```


## 3.3 Trabajando con varias columnas

En esta sección realizaremos el mismo trabajo pero para cada una de las columnas utilizando las distintas funciones creadas así como las dadas.

### 3.3.1 Outliers IQR

Para obtener los outliers IQR en alguna de las columnas, utilizaremos la función `claves_outliers_IQR_en_alguna_columna`:

```{r}
claves.outliers.IQR.en.alguna.columna <- claves_outliers_IQR_en_alguna_columna(datos.num, 1.5)
claves.outliers.IQR.en.alguna.columna
```

Como vemos, existen valores duplicados, por lo que nos quedamos con los únicos y con los que aparecen en más de una columna:

```{r}
claves.outliers.IQR.en.mas.de.una.columna <- unique(
	claves.outliers.IQR.en.alguna.columna[
		duplicated(claves.outliers.IQR.en.alguna.columna)
	]
)

claves.outliers.IQR.en.alguna.columna <- unique(claves.outliers.IQR.en.alguna.columna)

claves.outliers.IQR.en.mas.de.una.columna
claves.outliers.IQR.en.alguna.columna
nombres_filas(datos.num, claves.outliers.IQR.en.mas.de.una.columna)
nombres_filas(datos.num, claves.outliers.IQR.en.alguna.columna)
```

Podemos observar que en esta lista se encuentran los valores obtenidos mientras estudiabamos la última columna, así como muchas otras observaciones. Vamos a consultar los valores que tiene cada observación en las distintas columnas utilizando los datos normalizados para saber rápidamente en que columna tienen un valor inusual.

```{r}
datos.num.norm[claves.outliers.IQR.en.alguna.columna,]
```

De manera más visual también podemos utilizar un diagrama de cajas:

```{r}
diag_caja_juntos(datos.num, titulo = "Outliers en alguna columna", claves.a.mostrar = claves.outliers.IQR.en.alguna.columna)
```

Podemos ver como las principales columnas que están generando estos outliers son la quinta, novena y decimo tercera columnas, así como la tercera, cuarta, septima, decima y decimo primera columna también obtenemos algunos valores inusuales, aunque en menor número de observaciones

### 3.3.2 Tests de Hipótesis (OPCIONAL)

Al igual que con la columna 13, vamos a aplicar el test de Grubbs a cada una de las columnas de `datos.num`. Primero vamos a ver como es el ajuste con una distribución normal de forma gráfica:

```{r results = "hide"}
par(mfrow = c(2,3))
sapply(c(1:ncol(datos.num)), function(x) {
	ajusteNormal = fitdist(datos.num[, x] , "norm")
	denscomp (ajusteNormal,  xlab = names(datos.num)[x])
})
```

Como podemos ver, aunque la mayoría siguen una forma similar a la normal como vimos al principio del trabajo, vemos que pocas se ajustan claramente a esta, para comprobarlo estadisticamente vamos a lanzar el test de Grubbs en cada columna:

```{r}
sapply(c(1:ncol(datos.num)), function(x) {test_Grubbs(datos.num, x)})
```

Finalmente obtenemos que solo la columna `Ash` sigue una distribución normal.


# 4 Outliers Multivariantes

En este apartado utilizaremos técnicas estadísticas, técnicas basadas en distancias y técnicas basadas en clustering para encontrar outliers multivariantes. Es importante destacar que los outliers multivariantes, a diferencia de los outliers 1-variantes, no son simplemente outliers cuyos valores sean inusuales con respecto a sus columnas, también pueden ser valores usuales, pero que estén combinados de una forma inusual en una observación.


## 4.1 Métodos estadísticos basados en la distancia de Mahalanobis (OPCIONAL)

Estos métodos se basan en asegurar una garantía estadistica de que si un valor es etiquetado como outlier realmente lo es. Para este apartado utilizaremos técnicas que se basan en la distancia de Mahalanobis, estableciendo una hipótesis nula en la que se rechace que una observación es un outlier.  

### 4.1.1 Hipótesis de Normalidad

Los tests estadisticos que utilizaremos tienen como requisito que se siga una distribución normal multivariante, y una condición de esto es que cada columna del conjunto siga una distribución normal 1-variante. Vamos a comprobar primero esto:

```{r}
son.col.normales <- sapply(c(1:ncol(datos.num)), function(x) {
	test_Grubbs(datos.num, x)$es.distrib.norm
})

son.col.normales
```

Como vemos, solo una columna sigue una distribución normal, por lo que no podemos aplicar este método a este conjunto de datos. De cara a mostrar como se harían estas pruebas, se cambiarán un par de valores de `son.col.normales` pasando a `TRUE` las que visualmente se ajustan más a una normal de cara a hacer estas pruebas, aunque en principio si hubieramos obtenido estos resultados no debemos seguir adelante, ya que los resultados que obtenemos no son realistas.

```{r}
son.col.normales[4] <- TRUE
son.col.normales[9] <- TRUE
son.col.normales
```


Tras realizar esta comprobación necesitamos comprobar que el conjunto de las columnas sigue una distribución normal multivariante, esto lo haremos utilizando `mvn`:


```{r}
datos.num.distrib.norm <- datos.num[,son.col.normales]
datos.num.distrib.norm <- as.data.frame(datos.num.distrib.norm)
head(datos.num.distrib.norm)

# aplicar un test de normalidad multivariado
test.MVN = mvn(datos.num.distrib.norm, mvnTest = "energy")
test.MVN$multivariateNormality["MVN"]
test.MVN$multivariateNormality["p value"]
```

Si el p-value de este test es menor a 0.05 rechazaríamos la hipótesis nula y tendríamos garantías estadisticas de que los datos no siguen una distribución normal multivariante.

Como podemos ver, el p-value es cero, y como cabría esperar, si las columnas no siguen una distribución normal por si mismas, el conjunto de ellas no van a seguir una distribución normal multivariante. Aunque esto no se cumpla, de forma didactica seguiremos con este método para ver como se aplicaría.


### 4.1.2 Tests de hipótesis para detectar outliers

*AVISO*: Al solo obtener tener columna que sigue una distribución normal estos resultados no son relevantes, ya que no es aplicable en este caso, aun así he descrito como se realizaría. 

Al igual que en el guión de prácticas, utilizaremos la función `cerioli2010.fsrmcd.test` para obtener los outliers utilizando la distancia de Mahalanobis a través de una estimación de la matriz de covarianzas. Para verlo visualmente primero utilizaremos la función `corr.plot`:

```{r}
corr.plot(datos.num[,1], datos.num[,2])
```

Primero aplicaremos el test individual, equivalente al test de Grubbs, con el parámetro `signif.alpha` con un valor de 0.05:

```{r}
set.seed(2)

# de nuevo, datos.num.distrib.norm es solo una columna, necesitamos multiples, así que esta sección está comentada con como sería el código si tuvieramos múltiples columnas con una distribución normal
cerioli.test.individual <- cerioli2010.fsrmcd.test(datos.num.distrib.norm, signif.alpha = 0.05)

claves.test.individual <- which(cerioli.test.individual$outliers == TRUE)
claves.test.individual
```

También podemos lanzar el test de intersección para comprobar si cada uno de los valores es un outlier o no, penalizando el valor de significación, en este caso con un valor de $1 - (1 - 0.05)^{1/n}$:

```{r}
set.seed(2)

cerioli.test.interseccion <- cerioli2010.fsrmcd.test(datos.num.distrib.norm, signif.alpha = 1 - (1 - 0.05)^(1/nrow(datos.num.distrib.norm)))

claves.test.interseccion <- which(cerioli.test.interseccion$outliers == TRUE)
claves.test.interseccion
```

En el caso del test individual solo tendríamos garantía estadística de que el valor con mayor valor con distancia de Mahalanobis es un outlier, esto lo podemos ver ordenando de forma decreciente el vector de distancias obtenido:

```{r}
distancias.cerioli.test.interseccion.ordenado <- sort(cerioli.test.interseccion$mahdist.rw, decreasing = FALSE)
clave.mayor.dist.Mah <- order(cerioli.test.interseccion$mahdist.rw, decreasing = FALSE)[1]
clave.mayor.dist.Mah
plot(distancias.cerioli.test.interseccion.ordenado)
```

De nuevo recordar que estos resultados no son relevantes debido a que las columnas utilizadas no siguen una distribución normal, de forma que estos resultados no se tendrán en cuenta, simplemente se han realizado para explicar como se haría cada test en caso de tener otro conjunto de datos que si tenga varias columnas con una distribución normal.


## 4.2 Visualización de datos con un Biplot

De cara a obervar la distribución de todas las observaciones con respecto las variables vamos a utilizar un biplot: 

```{r}

biplot.outliers.IQR <- biplot_2_colores(datos.num,
										claves.outliers.IQR.en.alguna.columna,
										titulo.grupo.a.mostrar = "Outliers IQR",
										titulo = "Biplot Outliers IQR")
biplot.outliers.IQR
```

En este caso los porcentajes explicados no son muy altos (33.8 + 17.5 = 51.3), por lo que esta aproximación no es demasiado buena, aunque aun así podemos ver como, por ejemplo, los outliers IQR se encuentran por la misma zona. 

Utilizaremos este tipo de gráfico para observar los resultados de los métodos que utilizaremos.

## 4.3 Métodos basados en distancias: LOF

Los métodos basados en distancias nos permiten determinar observaciones que se encuentran alejadas del resto, permitiendo detectar outliers cuando no podemos aplicar métodos estadisticos, como en este caso. Es importante destacar que al basarse en distancias es necesario trabajar con los datos normalizados para que todas las columnas tengan la misma importancia.

El método que utilizaremos en este caso es el método LOF (local outlier factor), basado en la densidad local del conjunto de datos, considerando outliers a los puntos en las zonas del espacio con menor densidad.

Lo primero que haremos será establecer el número de vecinos más cercanos que usaremos para llamar a la función `LOF`:

```{r}

num.vecinos.lof = 5
lof.scores <- LOF(datos.num.norm, k = num.vecinos.lof)
```

Una vez hemos obtenido la puntuación asignada por LOF a cada observación vamos a representarla gráficamente para ver si hay una clara distinción de datos con una puntuación alta:

```{r}
lof.scores.ordenados <- sort(lof.scores, decreasing = T) 

plot(lof.scores.ordenados)
```

En esta ocasión, a diferencia del guión de prácticas, no existe una clara distinción que separe las puntuaciones obtenidas, sin embargo vemos como claramente hay bastantes observaciones con una puntuación LOF bastante más alta que la mayoría. En este caso he considerado que hay nueve outliers utilizando las puntuaciones, los nueve puntos con valor mayor a $1.4$. Vamos a obtener los indices de estos nueve puntos (los nombres no se han considerado ya que en este conjunto de datos las filas no tienen nombre):

```{r}
num.outliers <- 9
claves.outliers.lof <- sapply(c(1:num.outliers), function(x) which(lof.scores == lof.scores.ordenados[x]))
claves.outliers.lof
```

Tras observar los indices que obtenemos podemos ver que no obtenemos ninguno de los indices obtenidos por el método IQR ni índices de las observaciones que se habían pensado como outliers en este dataset. Esto puede ser posible debido a que las 10 observaciones mantenidas como outliers pueden estar cerca en el espacio y la densidad de estos puntos hace que su puntuación LOF no sea tan alta.

Vamos a observar los outliers obtenidos por LOF:

```{r}
datos.num.norm[claves.outliers.lof,]
```

Podemos ver como en todas las observaciones marcadas como outliers por este método encontramos al menos una columna con valor inusual o muy inusual, lo que lleva a pensar que estos valores inusuales han sido los que han hecho que estos puntos se consideren alejados del resto.

Para comprobar esto vamos a escoger el punto con mayor puntuación LOF y representarlo gráficamente con cada pareja de columnas:

```{r}
clave.max.outlier.lof <- claves.outliers.lof[1]

colores <- rep("black", times = nrow(datos.num.norm))
colores[clave.max.outlier.lof] <- "red"
pairs(datos.num.norm, pch = 19, cex = 0.5, col = colores, lower.panel = NULL)
```

En este caso, aunque disponemos de muchas columnas, podemos ver claramente como en muchas combinaciones el mayor outlier obtenido por LOF (punto rojo) está totalmente separado de los demás puntos, como puede ser el caso en la interacción de `Alcohol` y `Alcalinity_of_ash` o la de `Magnesium` y `Hue`, entre otras.

De cara a ver la interacción de todas las variables en conjunto vamos a utilizar un biplot:

```{r}
biplot.max.outlier.lof <- biplot_2_colores(datos.num.norm, clave.max.outlier.lof, titulo = "Mayor outlier LOF")
biplot.max.outlier.lof
```

En este caso en el biplot podemos ver que existen puntos en zonas con menor densidad que el mayor outlier LOF, sin embargo recordemos que este gráfico tan solo es capaz de explicar el $51.3\%$ de los datos. A pesar de esto vemos que el punto está en una zona relativamente alejada, donde no existen muchos puntos, así que esto sumado a que no se está representando casi la mitad de la información del conjunto de datos puede explicar que visualmente no se visualice el resultado del método LOF de forma gráfica.

## 4.4 Métodos basados en Clustering

Vamos a probar otro método basado en distancias, en esta ocasión detectaremos outliers utilizando la distancia de cada observación al centroide del cluster asignado. De cara a utilizar este método podemos utilizar distintos algoritmos de clustering.

### 4.4.1 Clustering usando k-means

En esta sección utilizaremos el algoritmo k-means para crear los clusters. Como sabemos, el dataset cuenta con información de dos clases distintas además de los datos de una tercera clase que actuan como outliers. Por este motivo, y sabiendo que son diez el número de elementos que actuan como outliers se ha escogido lanzar esta búsqueda de outliers buscando los diez elementos más alejados de sus centroides, utilizando dos clusters.

```{r}
num.outliers <- 10
num.clusters <- 2
set.seed(2)
```

Tras esto pasamos a entrenar un modelo k-means con los datos normalizados ya que se trata de un método que tiene en cuenta las distancias.

```{r}
modelo.kmeans <- kmeans(datos.num.norm, num.clusters)

asignaciones.clustering.kmeans <- modelo.kmeans$cluster
centroides.normalizados <- modelo.kmeans$centers


head(asignaciones.clustering.kmeans)
centroides.normalizados
```


Tras obtener los centroides los desnormalizamos para que estén en el rango real de las columnas:

```{r}
centroides.desnormalizados <- desnormaliza(datos.num, centroides.normalizados)
centroides.desnormalizados
```

Y tras obtener los centroides en una escala con respecto a los datos originales, obtenemos los outliers con respecto a los centroides:

```{r}
top.outliers.kmeans <- top_clustering_outliers(datos.num.norm,
											   asignaciones.clustering.kmeans,
											   centroides.normalizados,
											   num.outliers)

claves.outliers.kmeans <- top.outliers.kmeans$claves
distancias.outliers.centroides <- top.outliers.kmeans$distancias

claves.outliers.kmeans

distancias.outliers.centroides
```


Podemos ver como algunos de los índices coinciden con las observaciones que son outliers, sin embargo no todos coinciden. Esto puede deberse a que los diez datos outliers han movido el centroide real del cluster, haciendo que datos que realmente no son outliers sean considerados como tal. Esto lo podemos comprobar de forma gráfica con el biplot, aunque hemos de recordar que en nuestro caso solo representa la mitad de la información del dataset:

```{r}
biplot_outliers_clustering(datos.num,
						   titulo = "Outliers k-means",
						   asignaciones.clustering = asignaciones.clustering.kmeans,
						   claves.outliers = claves.outliers.kmeans)
```

Vemos como la explicación dada es plausible, ya que los datos marcados como outliers son los más alejados del centro en la zona superior del segundo cluster así como un elemento bastante alejado del primer cluster.

Además, estos datos son los que ya habíamos visto como outliers con el método IQR, como podemos ver en un diagrama de cajas:

```{r}
diag_caja_juntos(datos.num, "Outliers k-means", claves.outliers.kmeans)

```


### 4.4.2 Clustering usando medoides (OPCIONAL)

Utilizaremos el método de clustering PAM a través del paquete `cluster`:

```{r}

set.seed(2)
matriz.distancias = dist(datos.num.norm)
modelo.pam        = pam(matriz.distancias , k = num.clusters)
```

Tras obtener el modelo ajustado a los datos gracias a la matriz de distancias podemos obtener las asignaciones de medoides de la siguiente forma:

```{r}
asignaciones.clustering.pam = modelo.pam$clustering   
nombres.medoides = modelo.pam$medoids    
medoides = datos.num[nombres.medoides, ]
medoides.normalizados = datos.num.norm[nombres.medoides, ]

nombres.medoides

medoides

medoides.normalizados
```

Y al igual que utilizando k-means, podemos obtener los outliers con la función `top_clustering_outliers`:


```{r}
top.outliers.pam <- top_clustering_outliers(datos.num.norm,
											   asignaciones.clustering.pam,
											   medoides.normalizados,
											   num.outliers)

claves.outliers.pam <- top.outliers.pam$claves

claves.outliers.pam
```

En este caso solo la novena observación es marcada como outlier siendo uno de los outliers originales, mientras que el resto son outliers encontrados también por otros métodos como el IQR, o el k-means, así que vamos a ver de forma gráfica en un biplot como se distribuyen los outliers encontrados:

```{r}
biplot_outliers_clustering(datos.num,
						   titulo = "Outliers PAM",
						   asignaciones.clustering = asignaciones.clustering.pam,
						   claves.outliers = claves.outliers.pam)


```

Al igual que en otros casos, vemos que los outliers encontrados se tratan de valores extremos en algunas variables, aunque en este caso vemos como ha encontrado algunos nuevos (la observación 48, 79 y 12) que se tratan de combinaciones raras de valores, por lo que este método nos ha servido para conocer también estos nuevos casos.


## 4.5 Análisis de los outliers multivariantes puros

En esta sección vamos a obtener los outliers multivariantes puros, es decir, outliers multivariantes pero no 1-variantes. Vamos a comenzar obteniendo los outliers LOF que no son outliers IQR:

```{r}
claves.outliers.lof.no.IQR <- setdiff(claves.outliers.lof, claves.outliers.IQR.en.alguna.columna)

claves.outliers.IQR.en.alguna.columna
claves.outliers.lof

claves.outliers.lof.no.IQR

datos.num.norm[claves.outliers.lof.no.IQR,]
```

Como vemos, el número de outliers LOF que no son outliers IQR es tan solo la observación número 23, que como vemos no tiene ningún valor inusual, así que vamos a ver en un biplot donde se encuetra este punto:

```{r}
biplot.outliers.puros <- biplot_2_colores(datos.num.norm, 
										 claves.outliers.lof.no.IQR, 
										 titulo = "Outliers LOF (excluidos los que son IQR)")

biplot.outliers.puros


```

En el biplot podemos ver que esta observación a priori no es muy rara, está en una zona de puntos relativamente densa, pero debemos recordar que en nuestro caso la representación del biplot no es demasiado buena y su problema sea una combinación de valores extraña.

















